---
title: Results
date: "2020-11-10T00:00:00+01:00"
draft: false
share: false
commentable: false
editable: false

# Optional header image (relative to `static/media/` folder).
header:
  caption: ""
  image: ""



---

## Event recording

<div style="padding:48.24% 0 0 0;position:relative;"><iframe src="https://player.vimeo.com/video/620052580?h=f53433206d&amp;badge=0&amp;autopause=0&amp;player_id=0&amp;app_id=58479" frameborder="0" allow="autoplay; fullscreen; picture-in-picture" allowfullscreen style="position:absolute;top:0;left:0;width:100%;height:100%;" title="video_crossmoda"></iframe></div><script src="https://player.vimeo.com/api/player.js"></script>

## Leaderboard
<table class="dataframe" border="0">
  <thead>
    <tr style="text-align: right;">
      <th>Team</th>
      <th>Ranking</th>
      <th>VS_Dice</th>
      <th>VS_ASSD</th>
      <th>Cochlea_Dice</th>
      <th>Cochlea_ASSD</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Samoyed</td>
      <td>1</td>
      <td>0.8297</td>
      <td>0.5232</td>
      <td>0.8488</td>
      <td>0.3424</td>
    </tr>
    <tr>
      <td>PKU_BIALAB</td>
      <td>2</td>
      <td>0.8707</td>
      <td>0.3660</td>
      <td>0.7978</td>
      <td>0.2955</td>
    </tr>
    <tr>
      <td>jwc-rad</td>
      <td>3</td>
      <td>0.8288</td>
      <td>1.0436</td>
      <td>0.8217</td>
      <td>0.2858</td>
    </tr>
    <tr>
      <td>MIP</td>
      <td>4</td>
      <td>0.7995</td>
      <td>1.2902</td>
      <td>0.8248</td>
      <td>0.1822</td>
    </tr>
    <tr>
      <td>PremiLab</td>
      <td>5</td>
      <td>0.7727</td>
      <td>2.7762</td>
      <td>0.7967</td>
      <td>0.2936</td>
    </tr>
    <tr>
      <td>epione-liryc</td>
      <td>6</td>
      <td>0.7860</td>
      <td>2.0568</td>
      <td>0.7658</td>
      <td>0.3858</td>
    </tr>
    <tr>
      <td>MedICL</td>
      <td>7</td>
      <td>0.7756</td>
      <td>3.0634</td>
      <td>0.7445</td>
      <td>0.5333</td>
    </tr>
    <tr>
      <td>DBMI_pitt</td>
      <td>8</td>
      <td>0.4734</td>
      <td>10.9950</td>
      <td>0.7969</td>
      <td>0.5086</td>
    </tr>
    <tr>
      <td>Hi-Lib</td>
      <td>9</td>
      <td>0.6686</td>
      <td>4.3944</td>
      <td>0.6649</td>
      <td>1.2663</td>
    </tr>
    <tr>
      <td>smriti16109</td>
      <td>10</td>
      <td>0.7230</td>
      <td>2.9876</td>
      <td>0.5131</td>
      <td>0.9523</td>
    </tr>
    <tr>
      <td>IMI</td>
      <td>11</td>
      <td>0.6004</td>
      <td>4.4732</td>
      <td>0.4281</td>
      <td>9.8191</td>
    </tr>
    <tr>
      <td>GapMIND</td>
      <td>12</td>
      <td>0.6081</td>
      <td>3.8377</td>
      <td>0.5176</td>
      <td>1.6570</td>
    </tr>
    <tr>
      <td>gabybaldeon</td>
      <td>13</td>
      <td>0.6232</td>
      <td>7.5786</td>
      <td>0.3987</td>
      <td>3.9180</td>
    </tr>
    <tr>
      <td>SEU_Chen</td>
      <td>14</td>
      <td>0.1142</td>
      <td>38.0744</td>
      <td>0.4945</td>
      <td>14.0109</td>
    </tr>
    <tr>
      <td>skjp</td>
      <td>15</td>
      <td>0.2104</td>
      <td>24.4830</td>
      <td>0.2139</td>
      <td>15.6275</td>
    </tr>
    <tr>
      <td>IRA</td>
      <td>16</td>
      <td>0.1193</td>
      <td>30.8389</td>
      <td>0.2142</td>
      <td>19.5226</td>
    </tr>
  </tbody>
</table>

# Proposed approaches

## #1 - Samoyed
**Self-Training Based Unsupervised Cross-Modality Domain Adaptation for Vestibular Schwannoma and Cochlea Segmentation**

*Hyungseob Shin ; Hyeon Gyu Kim; Sewon Kim; Yohan Jun ; Taejoon Eo ; Dosik Hwang (Yonsei University)*

[Paper](/media/papers/samoyed.pdf)

<div style="padding:56.25% 0 0 0;position:relative;"><iframe src="https://player.vimeo.com/video/612629294?h=69e0bdfc9c&amp;badge=0&amp;autopause=0&amp;player_id=0&amp;app_id=58479" frameborder="0" allow="autoplay; fullscreen; picture-in-picture" allowfullscreen style="position:absolute;top:0;left:0;width:100%;height:100%;" title="Samoyed"></iframe></div><script src="https://player.vimeo.com/api/player.js"></script>


## #2 - PKU_BIALAB
**Unsupervised Domain Adaptation in Semantic Segmentation Based on Pixel Alignment and Self-Training (PAST)**

*Hexin Dong; Fei Yu; Jie Zhao; Bin Dong; Li Zhang (Peking University)*

[Paper](/media/papers/pku_bialab.pdf)

<div style="padding:56.25% 0 0 0;position:relative;"><iframe src="https://player.vimeo.com/video/612629033?h=7013f4e7a5&amp;badge=0&amp;autopause=0&amp;player_id=0&amp;app_id=58479" frameborder="0" allow="autoplay; fullscreen; picture-in-picture" allowfullscreen style="position:absolute;top:0;left:0;width:100%;height:100%;" title="PKU_BIALAB"></iframe></div><script src="https://player.vimeo.com/api/player.js"></script>

## #3 - jwc-rad
**Using Out-of-the-Box Frameworks for Unpaired Image Translation and Image Segmentation for the crossMoDA Challenge**

*Jae Won Choi (College of Medicine, Seoul National University)*

[Paper](/media/papers/jwc-rad.pdf)

<div style="padding:48.24% 0 0 0;position:relative;"><iframe src="https://player.vimeo.com/video/612747803?h=a5f5e9a537&amp;badge=0&amp;autopause=0&amp;player_id=0&amp;app_id=58479" frameborder="0" allow="autoplay; fullscreen; picture-in-picture" allowfullscreen style="position:absolute;top:0;left:0;width:100%;height:100%;" title="jwc-rad"></iframe></div><script src="https://player.vimeo.com/api/player.js"></script>

## #4 - MIP
**Cross-Modality Domain Adaptation for Vestibular Schwannoma and Cochlea Segmentation**

*JHan Liu; Yubo Fan; Can Cui; Dingjie Su; Andrew Mcneil; Benoit Dawant (Vanderbilt University)*

[Paper](/media/papers/mip.pdf)

<div style="padding:56.07% 0 0 0;position:relative;"><iframe src="https://player.vimeo.com/video/612628932?h=173adabba2&amp;badge=0&amp;autopause=0&amp;player_id=0&amp;app_id=58479" frameborder="0" allow="autoplay; fullscreen; picture-in-picture" allowfullscreen style="position:absolute;top:0;left:0;width:100%;height:100%;" title="MIP"></iframe></div><script src="https://player.vimeo.com/api/player.js"></script>

## #5 - PremiLab
**DAR-UNet: Dual Attention ResU-Net for CrossMoDa Challenge**

*Kai Yao; Zixian Su; Xi Yang; Kaizhu Huang; jie Sun (Xi'an Jiaotong-Liverpool University )*

[Paper](/media/papers/premilab.pdf)

<div style="padding:56.25% 0 0 0;position:relative;"><iframe src="https://player.vimeo.com/video/612629142?h=fc6f6c3c64&amp;badge=0&amp;autopause=0&amp;player_id=0&amp;app_id=58479" frameborder="0" allow="autoplay; fullscreen; picture-in-picture" allowfullscreen style="position:absolute;top:0;left:0;width:100%;height:100%;" title="PremiLab"></iframe></div><script src="https://player.vimeo.com/api/player.js"></script>


## #6 - epione-liryc
**Cross-Modality Domain Adaptation for Vestibular Schwannoma and cochlea segmentation from high-resolution T2 MRI (Epione-Liryc team)**

*Buntheng Ly; Victoriya Kashtanova; Yingyu Yang; Aurelien Maillot;
Marta Nunez-Garcia; Maxime Sermesant (INRIA)*

[Paper](/media/papers/epione-liryc.pdf)

<div style="padding:53.44% 0 0 0;position:relative;"><iframe src="https://player.vimeo.com/video/612629365?h=3508eb3106&amp;badge=0&amp;autopause=0&amp;player_id=0&amp;app_id=58479" frameborder="0" allow="autoplay; fullscreen; picture-in-picture" allowfullscreen style="position:absolute;top:0;left:0;width:100%;height:100%;" title="epione-liryc"></iframe></div><script src="https://player.vimeo.com/api/player.js"></script>

## #7 - MedICL
**Unsupervised Cross-modality Domain Adaptation for Segmentating Vestibular Schwannoma and Cochlea with Data Augmentation and Model Ensemble**

*Hao Li; Dewei Hu; Qibang Zhu; Kathleen E Larson; Huahong Zhang; Ipek Oguz*

[Paper](/media/papers/medicl.pdf)

<div style="padding:56.25% 0 0 0;position:relative;"><iframe src="https://player.vimeo.com/video/612628991?h=4d1ecb4d83&amp;badge=0&amp;autopause=0&amp;player_id=0&amp;app_id=58479" frameborder="0" allow="autoplay; fullscreen; picture-in-picture" allowfullscreen style="position:absolute;top:0;left:0;width:100%;height:100%;" title="MedICL"></iframe></div><script src="https://player.vimeo.com/api/player.js"></script>

## #8 - DBMI_pitt
**Fast Single Direction Translation for Brain Image Domain Adaptation**

*Yanwu Xu; Mingming Gong ; Kayhan Batmanghelich (University of Pittsburgh - University of Melbourne)*

[Paper](/media/papers/dbmi_pitt.pdf)

<div style="padding:41.87% 0 0 0;position:relative;"><iframe src="https://player.vimeo.com/video/613779256?h=5cddfb45fc&amp;badge=0&amp;autopause=0&amp;player_id=0&amp;app_id=58479" frameborder="0" allow="autoplay; fullscreen; picture-in-picture" allowfullscreen style="position:absolute;top:0;left:0;width:100%;height:100%;" title="crossMoDA_DBMI_Yanwu.mp4"></iframe></div><script src="https://player.vimeo.com/api/player.js"></script>

## #9 - MINDGap
**Learning on MIND features and noisy labels from image registration**

*Christian N Kruse; Mattias Heinrich (University of Luebeck)*

[Paper](/media/papers/mindgap.pdf)

<div style="padding:75% 0 0 0;position:relative;"><iframe src="https://player.vimeo.com/video/612628910?h=87b1582cfb&amp;badge=0&amp;autopause=0&amp;player_id=0&amp;app_id=58479" frameborder="0" allow="autoplay; fullscreen; picture-in-picture" allowfullscreen style="position:absolute;top:0;left:0;width:100%;height:100%;" title="MIND"></iframe></div><script src="https://player.vimeo.com/api/player.js"></script>

## #10 - Hi-Lib
**A GANs-based Modality Fusion and Data Augmentation for CrossMoDA Challeng**

*Jianghao Wu; Ran Gu; Shuwei Zhai; Wenhui Lei; Guotai Wang (University of Electronic Science and Technology of China)*

[Paper](/media/papers/hi-lib.pdf)

<div style="padding:56.25% 0 0 0;position:relative;"><iframe src="https://player.vimeo.com/video/612628882?h=c69981ab27&amp;badge=0&amp;autopause=0&amp;player_id=0&amp;app_id=58479" frameborder="0" allow="autoplay; fullscreen; picture-in-picture" allowfullscreen style="position:absolute;top:0;left:0;width:100%;height:100%;" title="HI-lib"></iframe></div><script src="https://player.vimeo.com/api/player.js"></script>

## #11 - smriti161096
**nn-Unet Training on CycleGAN-translated images for cross-modal domain adaptation in biomedical imaging**

*Smriti Joshi; Richard Osuala; Carlos MartÄ±n-Isla; Victor M. Campello; Carla
Sendra-Balcells; Karim Lekadir; Sergio Escalera (University of Barcelona)*

[Paper](/media/papers/smriti.pdf)

<div style="padding:56.25% 0 0 0;position:relative;"><iframe src="https://player.vimeo.com/video/612628843?h=e4cc47fd9d&amp;badge=0&amp;autopause=0&amp;player_id=0&amp;app_id=58479" frameborder="0" allow="autoplay; fullscreen; picture-in-picture" allowfullscreen style="position:absolute;top:0;left:0;width:100%;height:100%;" title="smriti161096"></iframe></div><script src="https://player.vimeo.com/api/player.js"></script>

## #12 - IMI
**MIND THE domain GAP: unsupervised modality independent deformable domain**

*Lasse Hansen; Mattias Heinrich (University of Luebeck)*

[Paper](/media/papers/imi.pdf)

<div style="padding:75% 0 0 0;position:relative;"><iframe src="https://player.vimeo.com/video/612628910?h=87b1582cfb&amp;badge=0&amp;autopause=0&amp;player_id=0&amp;app_id=58479" frameborder="0" allow="autoplay; fullscreen; picture-in-picture" allowfullscreen style="position:absolute;top:0;left:0;width:100%;height:100%;" title="MIND"></iframe></div><script src="https://player.vimeo.com/api/player.js"></script>


## #13 - gabybaldeon
**C-MADA: Unsupervised Cross-Modality Adversarial Domain Adaptation framework for medical Image Segmentation**

*Maria Baldeon Calisto; Susana K. Lai-Yuen (Universidad San Francisco de Quito, University of South Florida)*

[Paper](/media/papers/gabybaldeon.pdf)

<div style="padding:56.25% 0 0 0;position:relative;"><iframe src="https://player.vimeo.com/video/613573293?h=52b63bfb44&amp;badge=0&amp;autopause=0&amp;player_id=0&amp;app_id=58479" frameborder="0" allow="autoplay; fullscreen; picture-in-picture" allowfullscreen style="position:absolute;top:0;left:0;width:100%;height:100%;" title="CMADAPresentation.mp4"></iframe></div><script src="https://player.vimeo.com/api/player.js"></script>

## #14 - skjp
**MIND THE domain GAP: unsupervised modality independent deformable domain**

*Satoshi Kondo (Muroran Institute of Technology)*

[Paper](/media/papers/skjp.pdf)

<div style="padding:56.25% 0 0 0;position:relative;"><iframe src="https://player.vimeo.com/video/612629444?h=a677808f30&amp;badge=0&amp;autopause=0&amp;player_id=0&amp;app_id=58479" frameborder="0" allow="autoplay; fullscreen; picture-in-picture" allowfullscreen style="position:absolute;top:0;left:0;width:100%;height:100%;" title="skjp"></iframe></div><script src="https://player.vimeo.com/api/player.js"></script>

## #15 - SEU_chen
**A Cascade nnUNet By Mini-Entropy Domain Adaptation On Segmentation of Tumor and Cochlea**

*Chen Xiaofei (Southeast University)*

## #15 - IRA
**Comparing Unsupervised Domain Adaptation and Style-Transfer Methods in CrossMoDA Challenge**

*Arseniy Belkov; Boris Shirokikh ; Mikhail Belyaev (Moscow Institute of Physics and Technology, Skolkovo Institute of Science and Technology)*

[Paper](/media/papers/ira.pdf)