---
title: Results
date: "2020-11-10T00:00:00+01:00"
draft: false
share: false
commentable: false
editable: false

# Optional header image (relative to `static/media/` folder).
header:
  caption: ""
  image: ""



---

## Leaderboard
Metrics values and corresponding scores of submission. Median and interquartile values are presented. The best results are given in bold. Arrows indicate
favourable direction of each metric.
![image](https://user-images.githubusercontent.com/17268715/200420391-85db5c2e-3dc1-4a44-af0e-9933f2b22598.png)
## Event recording

<div style="padding:62.5% 0 0 0;position:relative;"><iframe src="https://player.vimeo.com/video/753986651?h=dc133c4c4b&amp;badge=0&amp;autopause=0&amp;player_id=0&amp;app_id=58479" frameborder="0" allow="autoplay; fullscreen; picture-in-picture" allowfullscreen style="position:absolute;top:0;left:0;width:100%;height:100%;" title="crossMoDA 2022 - presentation"></iframe></div><script src="https://player.vimeo.com/api/player.js"></script>

## Presentation
[Slides](/media/slides/crossmoda2022.pdf)

# Proposed approaches

## #1 - ne2e
**Unsupervised Domain Adaptation in Semantic Segmentation Based on Pixel Alignment and Self-Training (PAST)**

*Hexin Dong; Fei Yu; Mingze Yuan; Jie Zhao; Bin Dong; Li Zhang (Peking University)*

[Paper](/media/papers_2022/ne2e.pdf)


## #2 - MAI
**Multi-view Cross-Modality MR Image Translation for Vestibular Schwannoma and Cochlea Segmentation**

*Bogyeong Kang; Hyeonyeong Nam; Ji-Wung Han; Keun-Soo Heo; Tae-Eui Kam (Korea University)*

[Paper](/media/papers_2022/mai.pdf)


## #3 - LaTIM
**Tumor blending augmentation using one-shot generative learning for vestibular schwannoma and cochlea cross-modal segmentation**

*Guillaume Sallé; Pierre-Henri Conze; Julien Bert; Nicolas Boussion; Ulrike Schick; Dimitris Visvikis; Vincent Jaouen *

[Paper](/media/papers_2022/latim.pdf)


## #4 - Super_Polymerization
**Unsupervised Cross-Modality Domain Adaptation for Vestibular Schwannoma Segmentation and Koos Grade Prediction based on Semi-Supervised Contrastive Learning**

*Luyi Han; Yunzhi Huang; Tao Tan; and Ritse Mann (Radboud University Medical)*

[Paper](/media/papers_2022/superpolymerization.pdf)

<!-- 
## #5 - PremiLab
**DAR-UNet: Dual Attention ResU-Net for CrossMoDa Challenge**

*Kai Yao; Zixian Su; Xi Yang; Kaizhu Huang; jie Sun (Xi'an Jiaotong-Liverpool University )*

[Paper](/media/papers/premilab.pdf)



## #6 - Epione-Liryc
**Cross-Modality Domain Adaptation for Vestibular Schwannoma and cochlea segmentation from high-resolution T2 MRI (Epione-Liryc team)**

*Buntheng Ly; Victoriya Kashtanova; Yingyu Yang; Aurelien Maillot;
Marta Nunez-Garcia; Maxime Sermesant (INRIA)*

[Paper](/media/papers/Epione-Liryc.pdf)


## #7 - MedICL
**Unsupervised Cross-modality Domain Adaptation for Segmentating Vestibular Schwannoma and Cochlea with Data Augmentation and Model Ensemble**

*Hao Li; Dewei Hu; Qibang Zhu; Kathleen E Larson; Huahong Zhang; Ipek Oguz*

[Paper](/media/papers/medicl.pdf)


## #8 - DBMI_pitt
**Fast Single Direction Translation for Brain Image Domain Adaptation**

*Yanwu Xu; Mingming Gong ; Kayhan Batmanghelich (University of Pittsburgh - University of Melbourne)*

[Paper](/media/papers/dbmi_pitt.pdf)

## #9 - Hi-Lib
**A GANs-based Modality Fusion and Data Augmentation for CrossMoDA Challeng**

*Jianghao Wu; Ran Gu; Shuwei Zhai; Wenhui Lei; Guotai Wang (University of Electronic Science and Technology of China)*

[Paper](/media/papers/hi-lib.pdf)


## #10 - smriti161096
**nn-Unet Training on CycleGAN-translated images for cross-modal domain adaptation in biomedical imaging**

*Smriti Joshi; Richard Osuala; Carlos Martın-Isla; Victor M. Campello; Carla
Sendra-Balcells; Karim Lekadir; Sergio Escalera (University of Barcelona)*

[Paper](/media/papers/smriti.pdf)


## #11 - IMI
**MIND THE domain GAP: unsupervised modality independent deformable domain**

*Lasse Hansen; Mattias Heinrich (University of Luebeck)*

[Paper](/media/papers/imi.pdf)


## #12 - GapMIND
**Learning on MIND features and noisy labels from image registration**

*Christian N Kruse; Mattias Heinrich (University of Luebeck)*

[Paper](/media/papers/mindgap.pdf)



## #13 - gabybaldeon
**C-MADA: Unsupervised Cross-Modality Adversarial Domain Adaptation framework for medical Image Segmentation**

*Maria Baldeon Calisto; Susana K. Lai-Yuen (Universidad San Francisco de Quito, University of South Florida)*

[Paper](/media/papers/gabybaldeon.pdf)


## #14 - SEU_chen
**A Cascade nnUNet By Mini-Entropy Domain Adaptation On Segmentation of Tumor and Cochlea**

*Chen Xiaofei (Southeast University)*


## #15 - skjp
**MIND THE domain GAP: unsupervised modality independent deformable domain**

*Satoshi Kondo (Muroran Institute of Technology)*

[Paper](/media/papers/skjp.pdf)



## #16 - IRA
**Comparing Unsupervised Domain Adaptation and Style-Transfer Methods in CrossMoDA Challenge**

*Arseniy Belkov; Boris Shirokikh ; Mikhail Belyaev (Moscow Institute of Physics and Technology, Skolkovo Institute of Science and Technology)*

[Paper](/media/papers/ira.pdf) -->